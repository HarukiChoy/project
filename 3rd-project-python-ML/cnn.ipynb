{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "# df = pd.read_csv('final.csv')\n",
    "# X = df[df.columns[0:784]].to_numpy()\n",
    "# y = df[df.columns[-1]]\n",
    "# y = y.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 834036 files belonging to 39 classes.\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 15:19:10.231527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-25 15:19:10.232088: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22524 files belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "PATH = str(pathlib.Path().resolve())\n",
    "train_dir = os.path.join(PATH, 'Train')\n",
    "validation_dir = os.path.join(PATH, 'Validation')\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "IMG_SIZE = (28, 28)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "cnn = tf.keras.models.Sequential() \n",
    "cnn.add(tf.keras.layers.Input(shape=(28, 28, 1)))\n",
    "cnn.add(tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(IMG_SIZE[0], IMG_SIZE[1])))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "cnn.add(tf.keras.layers.Conv2D(64, (3,3), padding='valid', activation='relu'))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(activation = 'relu', units = 128))\n",
    "cnn.add(tf.keras.layers.Dense(activation = 'relu', units = 64))\n",
    "cnn.add(tf.keras.layers.Dense(activation = 'softmax', units = 39))\n",
    "cnn.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 15:19:15.950741: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-25 15:19:15.952205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/815 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.8646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 15:20:05.961795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/815 [==============================] - 52s 59ms/step - loss: 0.7570 - accuracy: 0.8646 - val_loss: 0.2663 - val_accuracy: 0.9209\n",
      "Epoch 2/15\n",
      "815/815 [==============================] - 49s 60ms/step - loss: 0.1974 - accuracy: 0.9348 - val_loss: 0.2294 - val_accuracy: 0.9316\n",
      "Epoch 3/15\n",
      "815/815 [==============================] - 51s 62ms/step - loss: 0.1729 - accuracy: 0.9417 - val_loss: 0.2278 - val_accuracy: 0.9295\n",
      "Epoch 4/15\n",
      "815/815 [==============================] - 50s 61ms/step - loss: 0.1582 - accuracy: 0.9460 - val_loss: 0.2213 - val_accuracy: 0.9328\n",
      "Epoch 5/15\n",
      "815/815 [==============================] - 52s 63ms/step - loss: 0.1477 - accuracy: 0.9488 - val_loss: 0.2149 - val_accuracy: 0.9324\n",
      "Epoch 6/15\n",
      "815/815 [==============================] - 50s 61ms/step - loss: 0.1393 - accuracy: 0.9511 - val_loss: 0.2185 - val_accuracy: 0.9342\n",
      "Epoch 7/15\n",
      "815/815 [==============================] - 52s 64ms/step - loss: 0.1326 - accuracy: 0.9529 - val_loss: 0.2266 - val_accuracy: 0.9315\n",
      "Epoch 8/15\n",
      "815/815 [==============================] - 51s 62ms/step - loss: 0.1253 - accuracy: 0.9551 - val_loss: 0.2215 - val_accuracy: 0.9374\n",
      "Epoch 9/15\n",
      "815/815 [==============================] - 51s 62ms/step - loss: 0.1199 - accuracy: 0.9566 - val_loss: 0.2179 - val_accuracy: 0.9401\n",
      "Epoch 10/15\n",
      "815/815 [==============================] - 52s 63ms/step - loss: 0.1142 - accuracy: 0.9581 - val_loss: 0.2330 - val_accuracy: 0.9384\n",
      "Epoch 11/15\n",
      "815/815 [==============================] - 51s 62ms/step - loss: 0.1083 - accuracy: 0.9601 - val_loss: 0.2560 - val_accuracy: 0.9304\n",
      "Epoch 12/15\n",
      "815/815 [==============================] - 52s 63ms/step - loss: 0.1047 - accuracy: 0.9612 - val_loss: 0.2512 - val_accuracy: 0.9394\n",
      "Epoch 13/15\n",
      "815/815 [==============================] - 51s 62ms/step - loss: 0.1001 - accuracy: 0.9624 - val_loss: 0.2637 - val_accuracy: 0.9392\n",
      "Epoch 14/15\n",
      "815/815 [==============================] - 50s 61ms/step - loss: 0.0959 - accuracy: 0.9636 - val_loss: 0.2568 - val_accuracy: 0.9407\n",
      "Epoch 15/15\n",
      "815/815 [==============================] - 52s 63ms/step - loss: 0.0912 - accuracy: 0.9656 - val_loss: 0.2626 - val_accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280ac35b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train_dataset, epochs = 15, validation_data = validation_dataset, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = cnn.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class number: 39\n",
      "All Label: ['#', '$', '&', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "class_name = len(train_dataset.class_names)\n",
    "class_arr = train_dataset.class_names\n",
    "print(\"Total class number: {}\".format(class_name))\n",
    "print(\"All Label: {}\".format(class_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2804 - accuracy: 0.9407\n"
     ]
    }
   ],
   "source": [
    "test_acc = cnn.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 17:08:54.957143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 621ms/step\n",
      "This is the index of prediction: 18\n",
      "The correct answer is: E\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './G.jpg'\n",
    "\n",
    "img_data = tf.keras.utils.load_img(\n",
    "    path,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=True\n",
    ")\n",
    "plt.imshow(img_data)\n",
    "\n",
    "array = tf.keras.preprocessing.image.img_to_array(img_data)\n",
    "array = np.array([array])\n",
    "\n",
    "predictions = cnn.predict(array)\n",
    "prediction = predictions.argmax()\n",
    "print('This is the index of prediction:', prediction)\n",
    "print('The correct answer is:', class_arr[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "This is the index of prediction: 7\n",
      "The correct answer is: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "file = './G.jpg'\n",
    "img = cv.imread(file, cv.IMREAD_GRAYSCALE)\n",
    "new_img = cv.resize(img, (28, 28), interpolation = cv.INTER_AREA)\n",
    "# np_img = np.array(new_img)\n",
    "\n",
    "array = np.array([new_img])\n",
    "predictions = cnn.predict(array)\n",
    "prediction = predictions.argmax()\n",
    "print('This is the index of prediction:', prediction)\n",
    "print('The correct answer is:', class_arr[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./recognition_v6.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cnn_mod \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m./recognition_v6.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/saving/save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    233\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at ./recognition_v6.h5"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cnn_mod = tf.keras.models.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "This is the index of prediction: 12\n",
      "The correct answer is: 9\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = './G.jpg'\n",
    "img = cv.imread(file)\n",
    "ret, output = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "output = cv.cvtColor(output, cv.COLOR_BGR2GRAY)\n",
    "new_img = cv.resize(output, (28, 28), interpolation = cv.INTER_AREA)\n",
    "# np_img = np.array(new_img)\n",
    "\n",
    "\n",
    "array = np.array([new_img])\n",
    "predictions = cnn_model.predict(array)\n",
    "prediction = predictions.argmax()\n",
    "print('This is the index of prediction:', prediction)\n",
    "print('The correct answer is:', class_arr[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29093b8d7fdc9c9cc281817a37219a88a604442368efe22e0596df777f5cfc01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
